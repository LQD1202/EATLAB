{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e77e423",
   "metadata": {},
   "source": [
    "Cam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98716eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import cv2\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# === B∆Ø·ªöC 1: C·∫ÆT VIDEO ===\n",
    "input_video = \"./dataset/1461_CH01_20250607193711_203711.mp4\"\n",
    "output_video_15min = \"./dataset/temp_15min.mp4\"\n",
    "start_time = \"00:10:00\"\n",
    "duration = \"00:05:00\"\n",
    "\n",
    "print(\"üî™ C·∫Øt video b·∫±ng ffmpeg...\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-ss\", start_time,\n",
    "    \"-i\", input_video,\n",
    "    \"-t\", duration,\n",
    "    \"-c\", \"copy\",\n",
    "    output_video_15min\n",
    "], check=True)\n",
    "print(\"‚úÖ C·∫Øt video th√†nh c√¥ng:\", output_video_15min)\n",
    "\n",
    "# === B∆Ø·ªöC 2: KH·ªûI T·∫†O MODEL V√Ä TRACKER ===\n",
    "model_path = \"./yolov12m-cam1/yolov12m-cam13/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "tracker = DeepSort(max_age=300)\n",
    "\n",
    "# === B∆Ø·ªöC 3: SETUP VIDEO OUTPUT ===\n",
    "cap = cv2.VideoCapture(output_video_15min)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output_video = \"./dataset/temp_15min_detected.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "# === V√ôNG QUAN T√ÇM ===\n",
    "x_center = (width // 2) + 100\n",
    "y_center = (height // 2) + 200\n",
    "y_thresh = 200\n",
    "\n",
    "# === BI·∫æN THEO D√ïI ===\n",
    "frame_count = 0\n",
    "count_pizza = 0\n",
    "tracked_ids = set()\n",
    "\n",
    "# === THAM S·ªê MODEL ===\n",
    "class_id_pizza = 67  # ID class \"pizza\"\n",
    "conf_thresh = 0.9\n",
    "\n",
    "# === V√íNG L·∫∂P D·ª∞ ƒêO√ÅN ===\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(\n",
    "        frame,\n",
    "        conf=conf_thresh,\n",
    "        classes=[class_id_pizza],\n",
    "        agnostic_nms=False,\n",
    "        max_det=100,\n",
    "        device=\"cuda:1\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    boxes = results[0].boxes\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    if boxes is not None and boxes.xyxy is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0].item())\n",
    "            cls = int(box.cls[0].item())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            detections.append(([x1, y1, w, h], conf, str(cls)))\n",
    "\n",
    "    # === C·∫¨P NH·∫¨T TRACKING ===\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.track_id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "\n",
    "        # T√¨m ƒë·ªô tin c·∫≠y g·∫ßn ƒë√∫ng\n",
    "        conf = 0.0\n",
    "        for det in detections:\n",
    "            bbox, det_conf, det_cls = det\n",
    "            x, y, w, h = bbox\n",
    "            if abs(x - x1) < 10 and abs(y - y1) < 10:\n",
    "                conf = det_conf\n",
    "                break\n",
    "\n",
    "        # T√≠nh t√¢m object\n",
    "        x_center_obj = (x1 + x2) // 2\n",
    "        y_center_obj = (y1 + y2) // 2\n",
    "\n",
    "        # L·ªçc object b√™n ph·∫£i khu v·ª±c quan t√¢m\n",
    "        if x_center_obj > x_center and y_thresh < y_center_obj < y_center and conf >= conf_thresh:\n",
    "            if track_id not in tracked_ids:\n",
    "                tracked_ids.add(track_id)\n",
    "                count_pizza += 1\n",
    "\n",
    "            # V·∫Ω box + ID\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "            cv2.putText(annotated_frame, f\"ID {track_id} ({conf:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng pizza ƒë√£ ƒë·∫øm\n",
    "    cv2.putText(annotated_frame, f\"Pizza Count: {count_pizza}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "    out.write(annotated_frame)\n",
    "    frame_count += 1\n",
    "    print(f\"üß† ƒê√£ x·ª≠ l√Ω frame {frame_count}\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"üé¨ Ho√†n t·∫•t! Video l∆∞u t·∫°i: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665539d",
   "metadata": {},
   "source": [
    "Cam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import cv2\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# === B∆Ø·ªöC 1: C·∫ÆT VIDEO ===\n",
    "input_video = \"./dataset/1465_CH02_20250607170555_172408.mp4\"\n",
    "output_video_15min = \"./dataset/temp_15min.mp4\"\n",
    "start_time = \"00:04:50\"\n",
    "duration = \"00:01:00\"\n",
    "\n",
    "print(\"üî™ C·∫Øt video b·∫±ng ffmpeg...\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-ss\", start_time,\n",
    "    \"-i\", input_video,\n",
    "    \"-t\", duration,\n",
    "    \"-c\", \"copy\",\n",
    "    output_video_15min\n",
    "], check=True)\n",
    "print(\"‚úÖ C·∫Øt video th√†nh c√¥ng:\", output_video_15min)\n",
    "\n",
    "# === B∆Ø·ªöC 2: KH·ªûI T·∫†O MODEL V√Ä TRACKER ===\n",
    "model_path = \"./yolov12m-cam2/yolov12m-cam26/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "tracker = DeepSort(max_age=300)\n",
    "\n",
    "# === B∆Ø·ªöC 3: ƒê·ªåC VIDEO V√Ä TRACK ===\n",
    "cap = cv2.VideoCapture(output_video_15min)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output_video = \"./dataset/temp_15min_detected_cam2.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "# === TH∆Ø M·ª§C L∆ØU FRAME ===\n",
    "output_frame_dir = \"./dataset/test/frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "tracked_ids = set()\n",
    "\n",
    "# === ƒê∆Ø·ªúNG CH√âO: y = -x + b ===\n",
    "b = height + 100  # ƒëi·ªÅu ch·ªânh n·∫øu mu·ªën ƒë∆∞·ªùng ch√©o cao h∆°n ho·∫∑c th·∫•p h∆°n\n",
    "\n",
    "# === THAM S·ªê PH√ÅT HI·ªÜN ===\n",
    "conf_thresh = 0.9\n",
    "target_cls = 0  # l·ªõp c·∫ßn ph√°t hi·ªán (v√≠ d·ª•: 0 = pizza)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(\n",
    "        frame,\n",
    "        conf=conf_thresh,\n",
    "        classes=[target_cls],\n",
    "        agnostic_nms=False,\n",
    "        max_det=100,\n",
    "        device=\"cuda:1\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes is not None and boxes.xyxy is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0].item())\n",
    "            cls = int(box.cls[0].item())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            detections.append(([x1, y1, w, h], conf, str(cls)))\n",
    "\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    pt1 = (0, b)\n",
    "    pt2 = (width, -width + b)\n",
    "    cv2.line(annotated_frame, pt1, pt2, (255, 0, 255), 2)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.track_id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "\n",
    "        # T√¨m l·∫°i ƒë·ªô tin c·∫≠y g·∫ßn ƒë√∫ng t·ª´ detection\n",
    "        conf = 0.0\n",
    "        for det in detections:\n",
    "            bbox, det_conf, det_cls = det\n",
    "            x, y, w, h = bbox\n",
    "            if abs(x - x1) < 10 and abs(y - y1) < 10:\n",
    "                conf = det_conf\n",
    "                break\n",
    "\n",
    "        # T√¢m object\n",
    "        x_center_obj = (x1 + x2) // 2\n",
    "        y_center_obj = (y1 + y2) // 2\n",
    "\n",
    "        # Ki·ªÉm tra n·∫øu object n·∫±m b√™n ph·∫£i (d∆∞·ªõi) ƒë∆∞·ªùng ch√©o\n",
    "        if conf >= conf_thresh:\n",
    "            tracked_ids.add(track_id)\n",
    "\n",
    "            # V·∫Ω bbox + ID\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "            cv2.putText(annotated_frame, f\"ID {track_id} ({conf:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3)\n",
    "\n",
    "    # V·∫Ω t·ªïng s·ªë object ƒë√£ ƒë·∫øm\n",
    "    cv2.putText(annotated_frame, f\"Pizza Count: {len(tracked_ids)}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "    # Ghi video v√† l∆∞u frame\n",
    "    out.write(annotated_frame)\n",
    "    frame_filename = os.path.join(output_frame_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "    cv2.imwrite(frame_filename, annotated_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# === K·∫æT TH√öC ===\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"üé¨ Done! Output video saved to: {output_video}\")\n",
    "print(f\"üñºÔ∏è C√°c frame ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_frame_dir}\")\n",
    "print(f\"üì¶ T·ªïng s·ªë object duy nh·∫•t n·∫±m b√™n ph·∫£i ƒë∆∞·ªùng ch√©o: {len(tracked_ids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220004a",
   "metadata": {},
   "source": [
    "Cam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import cv2\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# === B∆Ø·ªöC 1: C·∫ÆT VIDEO ===\n",
    "input_video = \"./dataset/1462_CH04_20250607210159_211703.mp4\"\n",
    "output_video_15min = \"./dataset/temp_15min.mp4\"\n",
    "start_time = \"00:10:00\"\n",
    "duration = \"00:01:00\"\n",
    "\n",
    "print(\"üî™ C·∫Øt video b·∫±ng ffmpeg...\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-ss\", start_time,\n",
    "    \"-i\", input_video,\n",
    "    \"-t\", duration,\n",
    "    \"-c\", \"copy\",\n",
    "    output_video_15min\n",
    "], check=True)\n",
    "print(\"‚úÖ C·∫Øt video th√†nh c√¥ng:\", output_video_15min)\n",
    "\n",
    "# === B∆Ø·ªöC 2: KH·ªûI T·∫†O MODEL V√Ä TRACKER ===\n",
    "model_path = \"./yolov12m-cam3/yolov12m-cam3/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "# === TH∆Ø M·ª§C L∆ØU FRAME ===\n",
    "output_frame_dir = \"./dataset/frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "# === VIDEO GHI OUTPUT ===\n",
    "cap = cv2.VideoCapture(output_video_15min)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = \"./dataset/temp_15min_detected_cam3.mp4\"\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "tracked_ids = set()\n",
    "\n",
    "CONF_THRESHOLD = 0.90  # Ch·ªâ v·∫Ω n·∫øu conf > 0.90\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(\n",
    "        frame,\n",
    "        conf=CONF_THRESHOLD,\n",
    "        classes=[0],\n",
    "        agnostic_nms=False,\n",
    "        max_det=100,\n",
    "        device=\"cuda:1\",\n",
    "        verbose=False,\n",
    "        iou=0.1\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    conf_map = {}  # l∆∞u box: conf ƒë·ªÉ v·∫Ω v·ªÅ sau\n",
    "\n",
    "    boxes = results[0].boxes\n",
    "    if boxes is not None and boxes.xyxy is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0].item())\n",
    "            cls = int(box.cls[0].item())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            detections.append(([x1, y1, w, h], conf, str(cls)))\n",
    "            conf_map[(int(x1), int(y1), int(x2), int(y2))] = conf\n",
    "\n",
    "    # === TRACKING ===\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "        track_box = (x1, y1, x2, y2)\n",
    "\n",
    "        # T√¨m l·∫°i conf g·∫ßn ƒë√∫ng theo IOU ho·∫∑c v·ªã tr√≠ box\n",
    "        matched_conf = 0.0\n",
    "        for (bx1, by1, bx2, by2), c in conf_map.items():\n",
    "            if abs(bx1 - x1) < 10 and abs(by1 - y1) < 10:\n",
    "                matched_conf = c\n",
    "                break\n",
    "\n",
    "        if matched_conf >= CONF_THRESHOLD:\n",
    "            tracked_ids.add(track_id)\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "            cv2.putText(annotated_frame, f\"ID {track_id} ({matched_conf:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3)\n",
    "\n",
    "    # Hi·ªÉn th·ªã ƒë·∫øm s·ªë l∆∞·ª£ng object duy nh·∫•t\n",
    "    cv2.putText(annotated_frame, f\"Pizza Count: {len(tracked_ids)}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "    # Ghi video v√† l∆∞u frame\n",
    "    out.write(annotated_frame)\n",
    "    frame_path = os.path.join(output_frame_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "    cv2.imwrite(frame_path, annotated_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# === K·∫æT TH√öC ===\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"üé¨ Done! Output video saved to: {output_video}\")\n",
    "print(f\"üñºÔ∏è C√°c frame ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_frame_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a98efb",
   "metadata": {},
   "source": [
    "Cam4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391653fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import cv2\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# === B∆Ø·ªöC 1: C·∫ÆT VIDEO ===\n",
    "input_video = \"./dataset/1464_CH02_20250607180000_190000.mp4\"\n",
    "output_video_15min = \"./temp_15min.mp4\"\n",
    "start_time = \"00:22:30\"\n",
    "duration = \"00:01:00\"\n",
    "\n",
    "print(\"üî™ C·∫Øt video b·∫±ng ffmpeg...\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-ss\", start_time,\n",
    "    \"-i\", input_video,\n",
    "    \"-t\", duration,\n",
    "    \"-c\", \"copy\",\n",
    "    output_video_15min\n",
    "], check=True)\n",
    "print(\"‚úÖ C·∫Øt video th√†nh c√¥ng:\", output_video_15min)\n",
    "\n",
    "# === B∆Ø·ªöC 2: KH·ªûI T·∫†O MODEL V√Ä TRACKER ===\n",
    "model_path = \"./yolov12m-cam4/yolov12m-cam46/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "# === TH∆Ø M·ª§C L∆ØU FRAME ===\n",
    "output_frame_dir = \"./frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "# === VIDEO GHI OUTPUT ===\n",
    "cap = cv2.VideoCapture(output_video_15min)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = \"./dataset/temp_15min_detected_cam4.mp4\"\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "tracked_ids = set()\n",
    "\n",
    "CONF_THRESHOLD = 0.90  # Ch·ªâ v·∫Ω n·∫øu conf > 0.90\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(\n",
    "        frame,\n",
    "        conf=CONF_THRESHOLD,\n",
    "        classes=[0],\n",
    "        agnostic_nms=False,\n",
    "        max_det=100,\n",
    "        device=\"cuda:1\",\n",
    "        verbose=False,\n",
    "        iou=0.1\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    conf_map = {}  # l∆∞u box: conf ƒë·ªÉ v·∫Ω v·ªÅ sau\n",
    "\n",
    "    boxes = results[0].boxes\n",
    "    if boxes is not None and boxes.xyxy is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0].item())\n",
    "            cls = int(box.cls[0].item())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            detections.append(([x1, y1, w, h], conf, str(cls)))\n",
    "            conf_map[(int(x1), int(y1), int(x2), int(y2))] = conf\n",
    "\n",
    "    # === TRACKING ===\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "        track_box = (x1, y1, x2, y2)\n",
    "\n",
    "        # T√¨m l·∫°i conf g·∫ßn ƒë√∫ng theo IOU ho·∫∑c v·ªã tr√≠ box\n",
    "        matched_conf = 0.0\n",
    "        for (bx1, by1, bx2, by2), c in conf_map.items():\n",
    "            if abs(bx1 - x1) < 10 and abs(by1 - y1) < 10:\n",
    "                matched_conf = c\n",
    "                break\n",
    "\n",
    "        if matched_conf >= CONF_THRESHOLD:\n",
    "            tracked_ids.add(track_id)\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "            cv2.putText(annotated_frame, f\"ID {track_id} ({matched_conf:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3)\n",
    "\n",
    "    # Hi·ªÉn th·ªã ƒë·∫øm s·ªë l∆∞·ª£ng object duy nh·∫•t\n",
    "    cv2.putText(annotated_frame, f\"Pizza Count: {len(tracked_ids)}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "    # Ghi video v√† l∆∞u frame\n",
    "    out.write(annotated_frame)\n",
    "    frame_path = os.path.join(output_frame_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "    cv2.imwrite(frame_path, annotated_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# === K·∫æT TH√öC ===\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"üé¨ Done! Output video saved to: {output_video}\")\n",
    "print(f\"üñºÔ∏è C√°c frame ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_frame_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29b377",
   "metadata": {},
   "source": [
    "Cam5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import cv2\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# === B∆Ø·ªöC 1: C·∫ÆT VIDEO ===\n",
    "input_video = \"./dataset/1465_CH02_20250607170555_172408.mp4\"\n",
    "output_video_15min = \"./dataset/temp_15min.mp4\"\n",
    "start_time = \"00:04:50\"\n",
    "duration = \"00:01:00\"\n",
    "\n",
    "print(\"üî™ C·∫Øt video b·∫±ng ffmpeg...\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-ss\", start_time,\n",
    "    \"-i\", input_video,\n",
    "    \"-t\", duration,\n",
    "    \"-c\", \"copy\",\n",
    "    output_video_15min\n",
    "], check=True)\n",
    "print(\"‚úÖ C·∫Øt video th√†nh c√¥ng:\", output_video_15min)\n",
    "\n",
    "# === B∆Ø·ªöC 2: KH·ªûI T·∫†O MODEL V√Ä TRACKER ===\n",
    "model_path = \"./yolov12m-cam5/yolov12m-cam56/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "tracker = DeepSort(max_age=300)\n",
    "\n",
    "# === B∆Ø·ªöC 3: ƒê·ªåC VIDEO V√Ä TRACK ===\n",
    "cap = cv2.VideoCapture(output_video_15min)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output_video = \"./dataset/temp_15min_detected_cam5.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "# === TH∆Ø M·ª§C L∆ØU FRAME ===\n",
    "output_frame_dir = \"./dataset/test/frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "tracked_ids = set()\n",
    "\n",
    "# === THAM S·ªê GI·ªöI H·∫†N KHU V·ª∞C ===\n",
    "y_center = height // 2                   # ch·ªâ l·∫•y object ph√≠a d∆∞·ªõi\n",
    "x_line = width // 2 + 200                # ch·ªâ l·∫•y object b√™n ph·∫£i ƒë∆∞·ªùng th·∫≥ng n√†y\n",
    "\n",
    "# === THAM S·ªê PH√ÅT HI·ªÜN ===\n",
    "conf_thresh = 0.9\n",
    "target_cls = 0  # l·ªõp c·∫ßn ph√°t hi·ªán\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(\n",
    "        frame,\n",
    "        conf=conf_thresh,\n",
    "        classes=[target_cls],\n",
    "        agnostic_nms=False,\n",
    "        max_det=100,\n",
    "        device=\"cuda:1\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes is not None and boxes.xyxy is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0].item())\n",
    "            cls = int(box.cls[0].item())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            detections.append(([x1, y1, w, h], conf, str(cls)))\n",
    "\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    # === V·∫Ω v√πng l·ªçc: ƒë∆∞·ªùng ngang + ƒë∆∞·ªùng d·ªçc\n",
    "    cv2.line(annotated_frame, (0, y_center), (width, y_center), (255, 0, 0), 2)  # ngang (xanh d∆∞∆°ng)\n",
    "    cv2.line(annotated_frame, (x_line, 0), (x_line, height), (255, 255, 0), 2)   # d·ªçc (cyan)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.track_id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "\n",
    "        # T√¨m l·∫°i ƒë·ªô tin c·∫≠y g·∫ßn ƒë√∫ng t·ª´ detection\n",
    "        conf = 0.0\n",
    "        for det in detections:\n",
    "            bbox, det_conf, det_cls = det\n",
    "            x, y, w, h = bbox\n",
    "            if abs(x - x1) < 10 and abs(y - y1) < 10:\n",
    "                conf = det_conf\n",
    "                break\n",
    "\n",
    "        # T√¢m ƒë·ªëi t∆∞·ª£ng\n",
    "        x_center_obj = (x1 + x2) // 2\n",
    "        y_center_obj = (y1 + y2) // 2\n",
    "\n",
    "        # Ch·ªâ ƒë·∫øm n·∫øu object n·∫±m b√™n ph·∫£i x_line v√† b√™n d∆∞·ªõi y_center\n",
    "        if conf >= conf_thresh and y_center_obj > y_center and x_center_obj > x_line:\n",
    "            tracked_ids.add(track_id)\n",
    "\n",
    "            # V·∫Ω bbox v√† ID\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "            cv2.putText(annotated_frame, f\"ID {track_id} ({conf:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3)\n",
    "\n",
    "    # Ghi t·ªïng s·ªë ID duy nh·∫•t\n",
    "    cv2.putText(annotated_frame, f\"Pizza Count: {len(tracked_ids)}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "    # Ghi video v√† l∆∞u frame\n",
    "    out.write(annotated_frame)\n",
    "    frame_filename = os.path.join(output_frame_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "    cv2.imwrite(frame_filename, annotated_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# === K·∫æT TH√öC ===\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"üé¨ Done! Output video saved to: {output_video}\")\n",
    "print(f\"üñºÔ∏è C√°c frame ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_frame_dir}\")\n",
    "print(f\"üì¶ T·ªïng s·ªë object duy nh·∫•t ƒë∆∞·ª£c track (b√™n ph·∫£i ƒë∆∞·ªùng chia): {len(tracked_ids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32110e",
   "metadata": {},
   "source": [
    "Cam6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2669d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî™ C·∫Øt video b·∫±ng ffmpeg...\n",
      "‚úÖ C·∫Øt video th√†nh c√¥ng: /media/hoangtv/0f9d3910-0ff9-406c-92e1-c2c8170ca6f4/Dat/EATLAB/dataset/temp_15min.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-liblensfun --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/media/hoangtv/0f9d3910-0ff9-406c-92e1-c2c8170ca6f4/Dat/EATLAB/dataset/1467_CH04_20250607180000_190000.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.9.107\n",
      "  Duration: 01:00:00.00, start: 0.000000, bitrate: 769 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/bt470bg/smpte170m), 1920x1080, 768 kb/s, 12 fps, 12 tbr, 12288 tbn, 24 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc61.33.100 libx264\n",
      "Output #0, mp4, to '/media/hoangtv/0f9d3910-0ff9-406c-92e1-c2c8170ca6f4/Dat/EATLAB/dataset/temp_15min.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/bt470bg/smpte170m), 1920x1080, q=2-31, 768 kb/s, 12 fps, 12 tbr, 12288 tbn, 12288 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc61.33.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  812 fps=0.0 q=-1.0 Lsize=   10554kB time=00:00:59.91 bitrate=1443.0kbits/s speed=8.49e+03x    \n",
      "video:10544kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.099362%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Done! Output video saved to: /media/hoangtv/0f9d3910-0ff9-406c-92e1-c2c8170ca6f4/Dat/EATLAB/dataset/temp_15min_detected_cam6.mp4\n",
      "üñºÔ∏è C√°c frame ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: /media/hoangtv/0f9d3910-0ff9-406c-92e1-c2c8170ca6f4/Dat/EATLAB/dataset/test/frames\n",
      "üì¶ T·ªïng s·ªë object duy nh·∫•t n·∫±m b√™n ph·∫£i ƒë∆∞·ªùng ch√©o: 1\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import cv2\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "def is_point_below_line(x, y, pt1, pt2):\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "\n",
    "    if x1 == x2:\n",
    "        # ƒê∆∞·ªùng th·∫≥ng ƒë·ª©ng => kh√¥ng x√°c ƒë·ªãnh \"d∆∞·ªõi\"\n",
    "        return x < x1  # ho·∫∑c x > x1 t√πy logic b·∫°n c·∫ßn\n",
    "    else:\n",
    "        # T√≠nh y tr√™n ƒë∆∞·ªùng t·∫°i ho√†nh ƒë·ªô x\n",
    "        y_on_line = y1 + (y2 - y1) * (x - x1) / (x2 - x1)\n",
    "        return y > y_on_line  # trong ·∫£nh: tr·ª•c y h∆∞·ªõng xu·ªëng => \"d∆∞·ªõi\" l√† y l·ªõn h∆°n\n",
    "\n",
    "# === B∆Ø·ªöC 1: C·∫ÆT VIDEO ===\n",
    "input_video = \"./dataset/1467_CH04_20250607180000_190000.mp4\"\n",
    "output_video_15min = \"./dataset/temp_15min.mp4\"\n",
    "start_time = \"00:01:10\"\n",
    "duration = \"00:01:00\"\n",
    "\n",
    "print(\"üî™ C·∫Øt video b·∫±ng ffmpeg...\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-ss\", start_time,\n",
    "    \"-i\", input_video,\n",
    "    \"-t\", duration,\n",
    "    \"-c\", \"copy\",\n",
    "    output_video_15min\n",
    "], check=True)\n",
    "print(\"‚úÖ C·∫Øt video th√†nh c√¥ng:\", output_video_15min)\n",
    "\n",
    "# === B∆Ø·ªöC 2: KH·ªûI T·∫†O MODEL V√Ä TRACKER ===\n",
    "model_path = \"./yolov12m-cam6/yolov12m-cam64/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "tracker = DeepSort(max_age=300)\n",
    "\n",
    "# === B∆Ø·ªöC 3: ƒê·ªåC VIDEO V√Ä TRACK ===\n",
    "cap = cv2.VideoCapture(output_video_15min)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output_video = \"./dataset/temp_15min_detected_cam6.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "# === TH∆Ø M·ª§C L∆ØU FRAME ===\n",
    "output_frame_dir = \"./dataset/test/frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "tracked_ids = set()\n",
    "\n",
    "# === ƒê∆Ø·ªúNG CH√âO: y = -x + b ===\n",
    "b = height + 300  # ƒëi·ªÅu ch·ªânh n·∫øu mu·ªën ƒë∆∞·ªùng ch√©o cao h∆°n ho·∫∑c th·∫•p h∆°n\n",
    "\n",
    "# === THAM S·ªê PH√ÅT HI·ªÜN ===\n",
    "conf_thresh = 0.9\n",
    "target_cls = 0  # l·ªõp c·∫ßn ph√°t hi·ªán (v√≠ d·ª•: 0 = pizza)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(\n",
    "        frame,\n",
    "        conf=conf_thresh,\n",
    "        classes=[target_cls],\n",
    "        agnostic_nms=False,\n",
    "        max_det=100,\n",
    "        device=\"cuda:1\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes is not None and boxes.xyxy is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0].item())\n",
    "            cls = int(box.cls[0].item())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            detections.append(([x1, y1, w, h], conf, str(cls)))\n",
    "\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    pt1 = (0, b)\n",
    "    pt2 = (width, max(0, -width + b))  # ƒë·∫£m b·∫£o to·∫° ƒë·ªô kh√¥ng √¢m\n",
    "\n",
    "    # V·∫Ω ƒë∆∞·ªùng\n",
    "    cv2.line(annotated_frame, pt1, pt2, (255, 0, 255), 2)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.track_id is None:\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "\n",
    "        # T√¨m l·∫°i ƒë·ªô tin c·∫≠y g·∫ßn ƒë√∫ng t·ª´ detection\n",
    "        conf = 0.0\n",
    "        for det in detections:\n",
    "            bbox, det_conf, det_cls = det\n",
    "            x, y, w, h = bbox\n",
    "            if abs(x - x1) < 10 and abs(y - y1) < 10:\n",
    "                conf = det_conf\n",
    "                break\n",
    "\n",
    "        # T√¢m object\n",
    "        x_center_obj = (x1 + x2) // 2\n",
    "        y_center_obj = (y1 + y2) // 2\n",
    "\n",
    "        # Ki·ªÉm tra n·∫øu object n·∫±m b√™n ph·∫£i (d∆∞·ªõi) ƒë∆∞·ªùng ch√©o\n",
    "        if conf >= conf_thresh and is_point_below_line(x, y, pt1,pt2):\n",
    "            tracked_ids.add(track_id)\n",
    "\n",
    "            # V·∫Ω bbox + ID\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "            cv2.putText(annotated_frame, f\"ID {track_id} ({conf:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3)\n",
    "\n",
    "    # V·∫Ω t·ªïng s·ªë object ƒë√£ ƒë·∫øm\n",
    "    cv2.putText(annotated_frame, f\"Pizza Count: {len(tracked_ids)}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "    # Ghi video v√† l∆∞u frame\n",
    "    out.write(annotated_frame)\n",
    "    frame_filename = os.path.join(output_frame_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "    cv2.imwrite(frame_filename, annotated_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# === K·∫æT TH√öC ===\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"üé¨ Done! Output video saved to: {output_video}\")\n",
    "print(f\"üñºÔ∏è C√°c frame ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_frame_dir}\")\n",
    "print(f\"üì¶ T·ªïng s·ªë object duy nh·∫•t n·∫±m b√™n ph·∫£i ƒë∆∞·ªùng ch√©o: {len(tracked_ids)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dat310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
